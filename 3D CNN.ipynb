{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Dropout,Conv3D, MaxPooling3D,Activation\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D\n",
    "import os\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_row = 100\n",
    "img_col = 100\n",
    "img_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "X_tr = []\n",
    "listing = os.listdir('videofortraining/jump/')\n",
    "for vid in listing:\n",
    "    vid = 'videofortraining/jump/'+vid\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    frameRate = cap.get(7)/(img_depth - 1)\n",
    "    newDimension = (img_row,img_col)\n",
    "    \n",
    "    frame_list = []\n",
    "    frame_list.append(0)\n",
    "    for i in range(img_depth):\n",
    "        f = math.floor((i + 1) * frameRate)\n",
    "        frame_list.append(f)\n",
    "    frame_list.append(int(cap.get(7)-2))\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if frameId in frame_list:\n",
    "            frame = cv2.resize(frame, newDimension, interpolation = cv2.INTER_AREA)\n",
    "            r, g, b = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "            gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "            frames.append(gray)\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    input=np.array(frames)\n",
    "\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n",
      "(100, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "listing = os.listdir('videofortraining/walk/')\n",
    "for vid in listing:\n",
    "    vid = 'videofortraining/walk/'+vid\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    frameRate = cap.get(7)/(img_depth - 1)\n",
    "    newDimension = (img_row,img_col)\n",
    "    \n",
    "    frame_list = []\n",
    "    frame_list.append(0)\n",
    "    for i in range(img_depth - 2):\n",
    "        f = math.floor((i + 1) * frameRate)\n",
    "        frame_list.append(f)\n",
    "    frame_list.append(int(cap.get(7)-2))\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if frameId in frame_list:\n",
    "            frame = cv2.resize(frame, newDimension, interpolation = cv2.INTER_AREA)\n",
    "            r, g, b = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "            gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "            frames.append(gray)\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    input=np.array(frames)\n",
    "\n",
    "    ipt=np.rollaxis(np.rollaxis(input,2,0),2,0)\n",
    "    print(ipt.shape)\n",
    "\n",
    "    X_tr.append(ipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 100, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "X_tr = np.array(X_tr)\n",
    "print(X_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "num_sample = len(X_tr)\n",
    "\n",
    "label = np.ones((num_sample))\n",
    "label[0:150] = 0\n",
    "label[150:300] = 1\n",
    "print(label)\n",
    "\n",
    "train_data = [X_tr,label]\n",
    "\n",
    "(X_train,Y_train) = (train_data[0],train_data[1])\n",
    "\n",
    "train_set = np.zeros((num_sample,1,img_row,img_col,img_depth))\n",
    "\n",
    "for sample in range(num_sample):\n",
    "    train_set[sample][0][:][:][:] = X_train[sample][:][:][:]\n",
    "\n",
    "patch_size = 10\n",
    "#print(train_set.shape)\n",
    "\n",
    "batch_size = 2\n",
    "num_class = 2\n",
    "num_epoch = 50\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train,num_class)\n",
    "#print(Y_train)\n",
    "\n",
    "num_filter = [32,32]\n",
    "num_pooling = [3,3]\n",
    "num_conv = [5,5]\n",
    "\n",
    "train_set = train_set.astype('float32')\n",
    "train_set -= np.mean(train_set)\n",
    "train_set /= np.max(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jasongao/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasongao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(128, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "  import sys\n",
      "/home/jasongao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(2, kernel_initializer=\"normal\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution3D(data_format = 'channels_first',filters = num_filter[0],kernel_size = (5,5,5),input_shape = (1,img_row,img_col,img_depth),activation='relu'))\n",
    "model.add(MaxPooling3D(pool_size = [3,3,3]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,init = 'normal',activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,init = 'normal'))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'RMSprop',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new,X_val_new,Y_train_new,Y_val_new = train_test_split(train_set,Y_train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasongao/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/50\n",
      "240/240 [==============================] - 66s 277ms/step - loss: 1.5075 - accuracy: 0.5125 - val_loss: 0.6865 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.9586 - accuracy: 0.6583 - val_loss: 0.6266 - val_accuracy: 0.6833\n",
      "Epoch 3/50\n",
      "240/240 [==============================] - 66s 274ms/step - loss: 0.7959 - accuracy: 0.6458 - val_loss: 1.0179 - val_accuracy: 0.5667\n",
      "Epoch 4/50\n",
      "240/240 [==============================] - 67s 277ms/step - loss: 0.7487 - accuracy: 0.6750 - val_loss: 0.6473 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "240/240 [==============================] - 84s 349ms/step - loss: 0.7405 - accuracy: 0.7000 - val_loss: 0.7077 - val_accuracy: 0.6167\n",
      "Epoch 6/50\n",
      "240/240 [==============================] - 86s 357ms/step - loss: 0.6936 - accuracy: 0.7292 - val_loss: 0.6541 - val_accuracy: 0.6667\n",
      "Epoch 7/50\n",
      "240/240 [==============================] - 85s 356ms/step - loss: 0.6565 - accuracy: 0.7167 - val_loss: 1.0720 - val_accuracy: 0.6000\n",
      "Epoch 8/50\n",
      "240/240 [==============================] - 82s 343ms/step - loss: 0.6507 - accuracy: 0.7875 - val_loss: 1.0999 - val_accuracy: 0.6833\n",
      "Epoch 9/50\n",
      "240/240 [==============================] - 86s 358ms/step - loss: 0.6973 - accuracy: 0.8042 - val_loss: 2.2906 - val_accuracy: 0.3833\n",
      "Epoch 10/50\n",
      "240/240 [==============================] - 86s 358ms/step - loss: 0.6045 - accuracy: 0.8208 - val_loss: 1.0445 - val_accuracy: 0.6833\n",
      "Epoch 11/50\n",
      "240/240 [==============================] - 86s 356ms/step - loss: 0.4027 - accuracy: 0.8417 - val_loss: 1.3697 - val_accuracy: 0.7667\n",
      "Epoch 12/50\n",
      "240/240 [==============================] - 86s 357ms/step - loss: 0.4546 - accuracy: 0.8833 - val_loss: 1.7435 - val_accuracy: 0.5833\n",
      "Epoch 13/50\n",
      "240/240 [==============================] - 86s 357ms/step - loss: 0.2934 - accuracy: 0.9167 - val_loss: 1.3997 - val_accuracy: 0.6167\n",
      "Epoch 14/50\n",
      "240/240 [==============================] - 86s 357ms/step - loss: 0.2608 - accuracy: 0.9375 - val_loss: 2.4698 - val_accuracy: 0.6000\n",
      "Epoch 15/50\n",
      "240/240 [==============================] - 84s 351ms/step - loss: 0.3080 - accuracy: 0.9167 - val_loss: 1.8943 - val_accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.3762 - accuracy: 0.9375 - val_loss: 1.6865 - val_accuracy: 0.7167\n",
      "Epoch 17/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1167 - accuracy: 0.9667 - val_loss: 2.4315 - val_accuracy: 0.6000\n",
      "Epoch 18/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.3344 - accuracy: 0.9292 - val_loss: 2.1497 - val_accuracy: 0.6500\n",
      "Epoch 19/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.3158 - accuracy: 0.9292 - val_loss: 3.3882 - val_accuracy: 0.5833\n",
      "Epoch 20/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1881 - accuracy: 0.9458 - val_loss: 3.1039 - val_accuracy: 0.6500\n",
      "Epoch 21/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1067 - accuracy: 0.9708 - val_loss: 3.2927 - val_accuracy: 0.6167\n",
      "Epoch 22/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0825 - accuracy: 0.9875 - val_loss: 5.1549 - val_accuracy: 0.6000\n",
      "Epoch 23/50\n",
      "240/240 [==============================] - 66s 276ms/step - loss: 0.3215 - accuracy: 0.9708 - val_loss: 3.0484 - val_accuracy: 0.6500\n",
      "Epoch 24/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.2325 - accuracy: 0.9750 - val_loss: 4.2478 - val_accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 4.6353 - val_accuracy: 0.6500\n",
      "Epoch 26/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.2170 - accuracy: 0.9667 - val_loss: 4.3540 - val_accuracy: 0.6667\n",
      "Epoch 27/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.3063 - accuracy: 0.9667 - val_loss: 3.1856 - val_accuracy: 0.7333\n",
      "Epoch 28/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1535 - accuracy: 0.9792 - val_loss: 3.5095 - val_accuracy: 0.6333\n",
      "Epoch 29/50\n",
      "240/240 [==============================] - 66s 276ms/step - loss: 0.1846 - accuracy: 0.9792 - val_loss: 5.0589 - val_accuracy: 0.5167\n",
      "Epoch 30/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1124 - accuracy: 0.9792 - val_loss: 3.3284 - val_accuracy: 0.6500\n",
      "Epoch 31/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0500 - accuracy: 0.9875 - val_loss: 7.7134 - val_accuracy: 0.4833\n",
      "Epoch 32/50\n",
      "240/240 [==============================] - 68s 282ms/step - loss: 0.0214 - accuracy: 0.9917 - val_loss: 4.6674 - val_accuracy: 0.6167\n",
      "Epoch 33/50\n",
      "240/240 [==============================] - 69s 288ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 4.7075 - val_accuracy: 0.6167\n",
      "Epoch 34/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.1022 - accuracy: 0.9875 - val_loss: 4.1461 - val_accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0887 - accuracy: 0.9792 - val_loss: 3.9944 - val_accuracy: 0.6167\n",
      "Epoch 36/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0989 - accuracy: 0.9792 - val_loss: 4.6120 - val_accuracy: 0.6000\n",
      "Epoch 37/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0080 - accuracy: 0.9958 - val_loss: 5.9138 - val_accuracy: 0.6167\n",
      "Epoch 38/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0628 - accuracy: 0.9792 - val_loss: 9.4067 - val_accuracy: 0.5833\n",
      "Epoch 39/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0555 - accuracy: 0.9958 - val_loss: 6.5859 - val_accuracy: 0.6000\n",
      "Epoch 40/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.8519 - val_accuracy: 0.6667\n",
      "Epoch 41/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.2057 - accuracy: 0.9875 - val_loss: 7.1671 - val_accuracy: 0.5667\n",
      "Epoch 42/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0100 - accuracy: 0.9958 - val_loss: 4.6357 - val_accuracy: 0.6333\n",
      "Epoch 43/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0036 - accuracy: 0.9958 - val_loss: 7.1082 - val_accuracy: 0.5833\n",
      "Epoch 44/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0041 - accuracy: 0.9958 - val_loss: 8.0833 - val_accuracy: 0.5333\n",
      "Epoch 45/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 8.9059 - val_accuracy: 0.5667\n",
      "Epoch 46/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.9528 - val_accuracy: 0.5500\n",
      "Epoch 47/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0158 - accuracy: 0.9958 - val_loss: 11.8426 - val_accuracy: 0.5333\n",
      "Epoch 48/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 3.5186e-04 - accuracy: 1.0000 - val_loss: 6.2398 - val_accuracy: 0.6667\n",
      "Epoch 49/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.0257 - accuracy: 0.9958 - val_loss: 9.5364 - val_accuracy: 0.5667\n",
      "Epoch 50/50\n",
      "240/240 [==============================] - 66s 275ms/step - loss: 0.2942 - accuracy: 0.9750 - val_loss: 8.2571 - val_accuracy: 0.6333\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train_new,Y_train_new,validation_data = (X_val_new,Y_val_new),batch_size = batch_size,nb_epoch = num_epoch,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model_w.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model_w.json')\n",
    "hist = loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-54eeff2d2c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['accuracy']\n",
    "val_acc=hist.history['val_accuracy']\n",
    "xc=range(num_epoch)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "286\n",
      "[0, 6.0, 12.0, 18.0, 24.0, 30.0, 36.0, 42.0, 48.0, 54.0, 60.0, 66.0, 72.0, 78.0, 84.0, 90.0, 96.0, 102.0, 108.0, 114.0, 120.0, 126.0, 132.0, 138.0, 144.0, 150.0, 156.0, 162.0, 168.0, 174.0, 180.0, 186.0, 192.0, 198.0, 204.0, 210.0, 216.0, 222.0, 228.0]\n",
      "(39, 100, 100)\n",
      "(29, 100, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "X_TEST = []\n",
    "frames = []\n",
    "count = 0\n",
    "listing = os.listdir('video_filmed/')\n",
    "for vid in listing:\n",
    "    vid = 'video_filmed/'+vid\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    frameRate = round(cap.get(5))\n",
    "    num_frame = round(cap.get(7))\n",
    "    print(frameRate)\n",
    "    print(num_frame)\n",
    "    \n",
    "    newDimension = (img_row,img_col)\n",
    "    sample_rate = 0.2 * frameRate \n",
    "    \n",
    "    s = 0\n",
    "    sample_frame = []\n",
    "    sample_frame.append(0)\n",
    "    while (s <= num_frame - 1 - img_depth * sample_rate):\n",
    "        s += sample_rate \n",
    "        sample_frame.append(s)\n",
    "    \n",
    "    print(sample_frame)\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if frameId in sample_frame:\n",
    "            frame = cv2.resize(frame, newDimension, interpolation = cv2.INTER_AREA)\n",
    "            r, g, b = frame[:,:,0], frame[:,:,1], frame[:,:,2]\n",
    "            gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "            frames.append(gray)\n",
    "            count +=1\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "\n",
    "    print(frames.shape)\n",
    "    \n",
    "   \n",
    "    \n",
    "    for i in range(count-img_depth):\n",
    "        frame_pack = []\n",
    "        for j in range(img_depth):\n",
    "            frame_pack.append(frames[i+j][:][:])    \n",
    "        X_TEST.append(frame_pack)  \n",
    "        \n",
    "       #f = np.array(frame_pack)\n",
    "       #print(f.shape)\n",
    "    \n",
    "    X_TEST = np.array(X_TEST)\n",
    "    X_TEST = np.rollaxis(np.rollaxis(X_TEST,3,1),3,1)\n",
    "    print(X_TEST.shape)\n",
    "    \n",
    "    TEST_set = np.zeros((count-img_depth,1,img_row,img_col,img_depth))\n",
    "\n",
    "    for sample in range(count-img_depth):\n",
    "        TEST_set[sample][0][:][:][:] = X_TEST[sample][:][:][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jasongao/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = hist.predict_proba(TEST_set)\n",
    "time = []\n",
    "prob = []\n",
    "time_label = []\n",
    "for i in range(count-img_depth):\n",
    "    time.append(i*0.2)\n",
    "    prob.append(prediction[i][0])\n",
    "    time_label.append([i*0.2,prediction[i][0]])\n",
    "\n",
    "#time_label = np.array(time_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7c600b2c90>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(time,prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('time_label_1','w') as f:\n",
    "    json.dump(str(time_label),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
